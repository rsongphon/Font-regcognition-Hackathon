{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os                                                                                                                                                                                        \n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n;\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-10T12:14:03.570219Z","iopub.execute_input":"2022-02-10T12:14:03.57092Z","iopub.status.idle":"2022-02-10T12:14:03.57879Z","shell.execute_reply.started":"2022-02-10T12:14:03.570874Z","shell.execute_reply":"2022-02-10T12:14:03.577878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Read meta data (ใช้รูป crop)\nmetadata = pd.read_csv('../input/font-detection-dataset-crop/label_train.csv')","metadata":{"execution":{"iopub.status.busy":"2022-02-10T12:14:03.580667Z","iopub.execute_input":"2022-02-10T12:14:03.581014Z","iopub.status.idle":"2022-02-10T12:14:04.057314Z","shell.execute_reply.started":"2022-02-10T12:14:03.580974Z","shell.execute_reply":"2022-02-10T12:14:04.056567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# add .png to make datagenerator  read file \nmetadata['parentId']  = metadata['parentId'] + '.png'","metadata":{"execution":{"iopub.status.busy":"2022-02-10T12:14:04.059928Z","iopub.execute_input":"2022-02-10T12:14:04.060417Z","iopub.status.idle":"2022-02-10T12:14:04.087783Z","shell.execute_reply.started":"2022-02-10T12:14:04.060377Z","shell.execute_reply":"2022-02-10T12:14:04.087056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check for class number\nprint('Num font:'+ str(len(metadata['fontFamily'].value_counts())))\nprint('Num size:'+ str(len(metadata['fontSize'].value_counts())))\nprint('Num weight:'+ str(len(metadata['fontWeight'].value_counts())))\nprint('Num style:'+ str(len(metadata['fontStyle'].value_counts())))","metadata":{"execution":{"iopub.status.busy":"2022-02-10T12:14:04.090174Z","iopub.execute_input":"2022-02-10T12:14:04.090465Z","iopub.status.idle":"2022-02-10T12:14:04.224317Z","shell.execute_reply.started":"2022-02-10T12:14:04.090426Z","shell.execute_reply":"2022-02-10T12:14:04.222016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# map Fontfamily to integer\nunique_vals = metadata['fontFamily'].unique()\nmetadata['fontFamily_int'] = metadata['fontFamily'].replace(to_replace=unique_vals,\n           value= list(range(len(unique_vals))))\n'''\n# map fontStyle integer\nunique_vals = metadata['fontStyle'].unique()\nmetadata['fontStyle_int'] = metadata['fontStyle'].replace(to_replace=unique_vals,\n           value= list(range(len(unique_vals))))\n\n# map fontWeight integer\nunique_vals = metadata['fontWeight'].unique()\nmetadata['fontWeight_int'] = metadata['fontWeight'].replace(to_replace=unique_vals,\n           value= list(range(len(unique_vals))))\n\n# map fontSize integer\nunique_vals = metadata['fontSize'].unique()\nmetadata['fontSize_int'] = metadata['fontSize'].replace(to_replace=unique_vals,\n           value= list(range(len(unique_vals))))\n'''\n","metadata":{"execution":{"iopub.status.busy":"2022-02-10T12:14:04.22575Z","iopub.execute_input":"2022-02-10T12:14:04.226194Z","iopub.status.idle":"2022-02-10T12:14:04.444608Z","shell.execute_reply.started":"2022-02-10T12:14:04.226145Z","shell.execute_reply":"2022-02-10T12:14:04.443954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metadata","metadata":{"execution":{"iopub.status.busy":"2022-02-10T12:14:04.448373Z","iopub.execute_input":"2022-02-10T12:14:04.450225Z","iopub.status.idle":"2022-02-10T12:14:04.475175Z","shell.execute_reply.started":"2022-02-10T12:14:04.450185Z","shell.execute_reply":"2022-02-10T12:14:04.474527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.applications import InceptionV3\nfrom tensorflow.keras.layers import BatchNormalization , Dense , Dropout , GlobalAveragePooling2D","metadata":{"execution":{"iopub.status.busy":"2022-02-10T12:14:04.479061Z","iopub.execute_input":"2022-02-10T12:14:04.480998Z","iopub.status.idle":"2022-02-10T12:14:04.486912Z","shell.execute_reply.started":"2022-02-10T12:14:04.480956Z","shell.execute_reply":"2022-02-10T12:14:04.486298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#define backbone model\ndef createInceptionV3(input_shape):\n    model = InceptionV3(\n    include_top=False,\n    weights=\"imagenet\",\n    input_shape=input_shape,\n    pooling=None)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-02-10T12:14:04.491334Z","iopub.execute_input":"2022-02-10T12:14:04.493886Z","iopub.status.idle":"2022-02-10T12:14:04.499886Z","shell.execute_reply.started":"2022-02-10T12:14:04.493847Z","shell.execute_reply":"2022-02-10T12:14:04.499215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# declare backbone model\nbasemodel = createInceptionV3((105, 105, 3))\nbasemodel.trainable = True ","metadata":{"execution":{"iopub.status.busy":"2022-02-10T12:14:04.504112Z","iopub.execute_input":"2022-02-10T12:14:04.505547Z","iopub.status.idle":"2022-02-10T12:14:06.389021Z","shell.execute_reply.started":"2022-02-10T12:14:04.505505Z","shell.execute_reply":"2022-02-10T12:14:06.388262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Top layer for 4 task\ndef create_model(base_model):\n    \n    x =  BatchNormalization()(base_model.output)\n    x =  GlobalAveragePooling2D()(x)\n    \n    # Font Family\n    dense_family = Dense(1024,activation = 'relu')(x)\n    dropout_family = Dropout(0.2)(dense_family)\n    output_family = Dense(10,activation = 'softmax')(dropout_family)\n \n    model = tf.keras.Model(inputs = base_model.input , outputs = output_family)\n    \n    return model\n    ","metadata":{"execution":{"iopub.status.busy":"2022-02-10T12:14:06.3918Z","iopub.execute_input":"2022-02-10T12:14:06.392077Z","iopub.status.idle":"2022-02-10T12:14:06.397799Z","shell.execute_reply.started":"2022-02-10T12:14:06.392041Z","shell.execute_reply":"2022-02-10T12:14:06.396855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create model\nmodel = create_model(basemodel)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T12:14:06.399187Z","iopub.execute_input":"2022-02-10T12:14:06.400116Z","iopub.status.idle":"2022-02-10T12:14:06.451763Z","shell.execute_reply.started":"2022-02-10T12:14:06.400078Z","shell.execute_reply":"2022-02-10T12:14:06.451083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-10T12:14:06.453102Z","iopub.execute_input":"2022-02-10T12:14:06.453422Z","iopub.status.idle":"2022-02-10T12:14:06.457063Z","shell.execute_reply.started":"2022-02-10T12:14:06.453385Z","shell.execute_reply":"2022-02-10T12:14:06.456357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(model)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T12:14:06.458267Z","iopub.execute_input":"2022-02-10T12:14:06.459098Z","iopub.status.idle":"2022-02-10T12:14:09.728833Z","shell.execute_reply.started":"2022-02-10T12:14:06.459059Z","shell.execute_reply":"2022-02-10T12:14:09.727929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_layer = len(model.layers)\nprint(num_layer)\nprint(len(model.trainable_variables))","metadata":{"execution":{"iopub.status.busy":"2022-02-10T12:14:09.731023Z","iopub.execute_input":"2022-02-10T12:14:09.731455Z","iopub.status.idle":"2022-02-10T12:14:09.74347Z","shell.execute_reply.started":"2022-02-10T12:14:09.731419Z","shell.execute_reply":"2022-02-10T12:14:09.742743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer =  tf.keras.optimizers.Adam(),\n              # กำหนด loss แบบ list ตาม order ที่create model or use 1 for all\n            loss = [tf.keras.losses.SparseCategoricalCrossentropy()],\n            metrics = ['acc']\n            )","metadata":{"execution":{"iopub.status.busy":"2022-02-10T12:14:09.745189Z","iopub.execute_input":"2022-02-10T12:14:09.745634Z","iopub.status.idle":"2022-02-10T12:14:09.777003Z","shell.execute_reply.started":"2022-02-10T12:14:09.745599Z","shell.execute_reply":"2022-02-10T12:14:09.776312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\ndef resize_image(image):\n    image = image.copy()\n    width = 299\n    heigth = 299\n    for i in range(int(width/image.shape[1])) :\n        if(image.shape[1] < width ):\n            image = np.hstack((image,image))\n        else:\n            break\n    for i in range(int(heigth/image.shape[0])) :\n        if(image.shape[0] < heigth ):\n            image = np.vstack((image,image))\n        else:\n            break\n    image = image[0:heigth,0:width].copy()\n    return image\npath = \"../input/fontregcogappman/font_detection_dataset/font_detection_dataset/\"\nimport glob\n# All files and directories ending with .txt and that don't begin with a dot:\nfiles_name_train = (glob.glob(path + \"image_train/*\"))\nfiles_name_test = (glob.glob(path + \"image_test/*\"))\nprint(files_name_train[0:2])\nimport cv2\nimport matplotlib.pyplot as plt\nfor file_path in files_name_train:\n    image = cv2.imread(file_path)\n    image = resize_image(image)\n    cv2.imwrite(file_path, image)\nfor file_path in files_name_test:\n    image = cv2.imread(file_path)\n    image = resize_image(image)\n    cv2.imwrite(file_path, image)\n'''","metadata":{"execution":{"iopub.status.busy":"2022-02-10T12:14:09.778532Z","iopub.execute_input":"2022-02-10T12:14:09.779084Z","iopub.status.idle":"2022-02-10T12:14:09.786878Z","shell.execute_reply.started":"2022-02-10T12:14:09.77904Z","shell.execute_reply":"2022-02-10T12:14:09.786034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create DATA PIPELINE \nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nDATA_PATH = '../input/font-detection-dataset-crop/'\n\n# use preprocessing_function match with model\nimage_generator = ImageDataGenerator(preprocessing_function = tf.keras.applications.inception_v3.preprocess_input)\ntrain_generator = image_generator.flow_from_dataframe(metadata[:-10000],# edit for metadata[:-10000] for real data\n                                    directory = DATA_PATH + 'image_train',\n                                    x_col ='parentId',\n                                    class_mode = 'raw',\n                                    y_col = 'fontFamily_int',\n                                    batch_size = 128,\n                                    seed = 69,\n                                    shuffle = True,\n                                    target_size=(105,105)\n                                    )\nvalidation_generator = image_generator.flow_from_dataframe(metadata[-10000:],# edit for metadata[-10000:] for real data\n                                    directory = DATA_PATH + 'image_train',\n                                    x_col ='parentId',\n                                    class_mode = 'raw',\n                                    y_col = 'fontFamily_int',\n                                    batch_size = 128,\n                                    seed = 69,\n                                    shuffle = True,\n                                    target_size=(105,105)\n                                    )\n","metadata":{"execution":{"iopub.status.busy":"2022-02-10T12:14:09.788849Z","iopub.execute_input":"2022-02-10T12:14:09.789376Z","iopub.status.idle":"2022-02-10T12:20:21.008178Z","shell.execute_reply.started":"2022-02-10T12:14:09.789337Z","shell.execute_reply":"2022-02-10T12:20:21.006672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Testing purpose\n#import matplotlib.pyplot as plt\n\n#plt.imshow(next(iter(train_generator))[0][0])\n#print(next(iter(train_generator))[0][0])\n'''\nori_img = plt.imread('../input/fontregcogappman/font_detection_dataset/font_detection_dataset/image_train/100045cf.png')\nplt.imshow(ori_img)\nimg = resize_image(ori_img)\nplt.imshow(img)\n'''","metadata":{"execution":{"iopub.status.busy":"2022-02-10T12:20:21.009629Z","iopub.execute_input":"2022-02-10T12:20:21.009908Z","iopub.status.idle":"2022-02-10T12:20:21.016451Z","shell.execute_reply.started":"2022-02-10T12:20:21.009871Z","shell.execute_reply":"2022-02-10T12:20:21.015619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights('../input/outputfontreg-1/inception_best.h5')","metadata":{"execution":{"iopub.status.busy":"2022-02-10T12:20:21.0178Z","iopub.execute_input":"2022-02-10T12:20:21.018765Z","iopub.status.idle":"2022-02-10T12:20:22.834502Z","shell.execute_reply.started":"2022-02-10T12:20:21.018695Z","shell.execute_reply":"2022-02-10T12:20:22.833753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create Checkpoint , Callback\nfrom tensorflow.keras.callbacks import Callback , EarlyStopping , ModelCheckpoint , ReduceLROnPlateau\n\ncheckpoint = ModelCheckpoint( filepath = './inception_best.h5', monitor='val_loss', verbose=0, save_best_only=True,\n                            save_weights_only=True, mode='auto', save_freq='epoch')\nearlystop =  EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0,\n                            mode='auto', baseline=None, restore_best_weights=False)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, mode='min')\n\ncallbacks = [checkpoint,earlystop,reduce_lr]","metadata":{"execution":{"iopub.status.busy":"2022-02-10T12:20:22.835625Z","iopub.execute_input":"2022-02-10T12:20:22.835884Z","iopub.status.idle":"2022-02-10T12:20:22.850388Z","shell.execute_reply.started":"2022-02-10T12:20:22.835849Z","shell.execute_reply":"2022-02-10T12:20:22.84951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fit model\nhistory = model.fit(x=train_generator,\n                    validation_data=validation_generator,\n                    epochs=25,\n                    callbacks=callbacks)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T12:20:22.852394Z","iopub.execute_input":"2022-02-10T12:20:22.852715Z","iopub.status.idle":"2022-02-10T12:34:53.543016Z","shell.execute_reply.started":"2022-02-10T12:20:22.852674Z","shell.execute_reply":"2022-02-10T12:34:53.541611Z"},"trusted":true},"execution_count":null,"outputs":[]}]}